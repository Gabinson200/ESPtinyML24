{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install netron"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWhO3doJEcSU",
        "outputId": "0a2ee50a-5979-4703-dd3f-144416d075ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting netron\n",
            "  Downloading netron-8.0.5-py3-none-any.whl.metadata (1.5 kB)\n",
            "Downloading netron-8.0.5-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: netron\n",
            "Successfully installed netron-8.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import netron\n",
        "import os\n",
        "\n",
        "# Path to your model file\n",
        "model_path = 'path_to_your_model.onnx'  # Replace with your model's path\n",
        "\n",
        "# Start Netron server\n",
        "netron_url = netron.start(model_path, port=8080)  # Specify a port if needed\n",
        "print(f\"Netron is running at {netron_url}\")"
      ],
      "metadata": {
        "id": "NhHhfe7eEe7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "KqvLRxvcEe9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-EUm0MerQfb"
      },
      "outputs": [],
      "source": [
        "def create_tiny_embedding_conv_model(is_training = True, dropout_rate=0.2):\n",
        "\n",
        "  if is_training:\n",
        "    dropout_rate = dropout_rate\n",
        "  input_frequency_size = 49\n",
        "  input_time_size = 40\n",
        "  fingerprint_4d = tf.reshape((1960, ),\n",
        "                              [-1, input_time_size, input_frequency_size, 1])\n",
        "\n",
        "  first_filter_width = 8\n",
        "  first_filter_height = 10\n",
        "  first_filter_count = 8\n",
        "  first_weights = tf.compat.v1.get_variable(\n",
        "      name='first_weights',\n",
        "      initializer=tf.compat.v1.truncated_normal_initializer(stddev=0.01),\n",
        "      shape=[first_filter_height, first_filter_width, 1, first_filter_count])\n",
        "  first_bias = tf.compat.v1.get_variable(\n",
        "      name='first_bias',\n",
        "      initializer=tf.compat.v1.zeros_initializer,\n",
        "      shape=[first_filter_count])\n",
        "  first_conv_stride_x = 2\n",
        "  first_conv_stride_y = 2\n",
        "\n",
        "  first_conv = tf.nn.conv2d(\n",
        "      input=fingerprint_4d, filters=first_weights,\n",
        "      strides=[1, first_conv_stride_y, first_conv_stride_x, 1],\n",
        "      padding='SAME') + first_bias\n",
        "  first_relu = tf.nn.relu(first_conv)\n",
        "  if is_training:\n",
        "    first_dropout = tf.nn.dropout(first_relu, rate=dropout_rate)\n",
        "\n",
        "  else:\n",
        "    first_dropout = first_relu\n",
        "\n",
        "  second_filter_width = 8\n",
        "  second_filter_height = 10\n",
        "  second_filter_count = 8\n",
        "  second_weights = tf.compat.v1.get_variable(\n",
        "      name='second_weights',\n",
        "      initializer=tf.compat.v1.truncated_normal_initializer(stddev=0.01),\n",
        "      shape=[\n",
        "          second_filter_height, second_filter_width, first_filter_count,\n",
        "          second_filter_count\n",
        "      ])\n",
        "  second_bias = tf.compat.v1.get_variable(\n",
        "      name='second_bias',\n",
        "      initializer=tf.compat.v1.zeros_initializer,\n",
        "      shape=[second_filter_count])\n",
        "  second_conv_stride_x = 8\n",
        "  second_conv_stride_y = 8\n",
        "  second_conv = tf.nn.conv2d(\n",
        "      input=first_dropout, filters=second_weights,\n",
        "      strides=[1, second_conv_stride_y, second_conv_stride_x, 1],\n",
        "      padding='SAME') + second_bias\n",
        "  second_relu = tf.nn.relu(second_conv)\n",
        "  if is_training:\n",
        "    second_dropout = tf.nn.dropout(second_relu, rate=dropout_rate)\n",
        "  else:\n",
        "    second_dropout = second_relu\n",
        "\n",
        "  second_dropout_shape = second_dropout.get_shape()\n",
        "  second_dropout_output_width = second_dropout_shape[2]\n",
        "  second_dropout_output_height = second_dropout_shape[1]\n",
        "  second_dropout_element_count = int(second_dropout_output_width *\n",
        "                                     second_dropout_output_height *\n",
        "                                     second_filter_count)\n",
        "  flattened_second_dropout = tf.reshape(second_dropout,\n",
        "                                        [-1, second_dropout_element_count])\n",
        "  label_count = 4\n",
        "  final_fc_weights = tf.compat.v1.get_variable(\n",
        "      name='final_fc_weights',\n",
        "      initializer=tf.compat.v1.truncated_normal_initializer(stddev=0.01),\n",
        "      shape=[second_dropout_element_count, label_count])\n",
        "  final_fc_bias = tf.compat.v1.get_variable(\n",
        "      name='final_fc_bias',\n",
        "      initializer=tf.compat.v1.zeros_initializer,\n",
        "      shape=[label_count])\n",
        "  final_fc = (\n",
        "      tf.matmul(flattened_second_dropout, final_fc_weights) + final_fc_bias)\n",
        "  if is_training:\n",
        "    return final_fc, dropout_rate\n",
        "  else:\n",
        "    return final_fc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_tiny_embedding_conv_model(is_training=True, dropout_rate=0.2):\n",
        "    input_frequency_size = 40\n",
        "    input_time_size = 49\n",
        "    label_count = 4\n",
        "\n",
        "    # Define the input\n",
        "    input_layer = tf.keras.layers.Input(shape=(1960,), name='input')\n",
        "\n",
        "    # Reshape the input to 4D\n",
        "    fingerprint_4d = tf.keras.layers.Reshape((input_time_size, input_frequency_size, 1))(input_layer)\n",
        "\n",
        "    # First convolutional layer\n",
        "    first_conv = tf.keras.layers.Conv2D(\n",
        "        filters=8,\n",
        "        kernel_size=(10, 8),\n",
        "        strides=(2, 2),\n",
        "        padding='same',\n",
        "        kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\n",
        "        bias_initializer=tf.keras.initializers.Zeros(),\n",
        "        name='first_conv'\n",
        "    )(fingerprint_4d)\n",
        "    first_relu = tf.keras.layers.ReLU(name='first_relu')(first_conv)\n",
        "    first_dropout = tf.keras.layers.Dropout(rate=dropout_rate if is_training else 0.0, name='first_dropout')(first_relu)\n",
        "\n",
        "    # Second convolutional layer\n",
        "    second_conv = tf.keras.layers.Conv2D(\n",
        "        filters=8,\n",
        "        kernel_size=(10, 8),\n",
        "        strides=(8, 8),\n",
        "        padding='same',\n",
        "        kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\n",
        "        bias_initializer=tf.keras.initializers.Zeros(),\n",
        "        name='second_conv'\n",
        "    )(first_dropout)\n",
        "    second_relu = tf.keras.layers.ReLU(name='second_relu')(second_conv)\n",
        "    second_dropout = tf.keras.layers.Dropout(rate=dropout_rate if is_training else 0.0, name='second_dropout')(second_relu)\n",
        "\n",
        "    # Flatten the output\n",
        "    flattened = tf.keras.layers.Flatten(name='flatten')(second_dropout)\n",
        "\n",
        "    # Fully connected layer\n",
        "    final_fc = tf.keras.layers.Dense(\n",
        "        units=label_count,\n",
        "        kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\n",
        "        bias_initializer=tf.keras.initializers.Zeros(),\n",
        "        activation=None,  # Logits output\n",
        "        name='final_fc'\n",
        "    )(flattened)\n",
        "\n",
        "    # Define the model\n",
        "    model = tf.keras.models.Model(inputs=input_layer, outputs=final_fc, name='tiny_embedding_conv_model')\n",
        "    return model\n",
        "\n",
        "# Create and summarize the model\n",
        "model = create_tiny_embedding_conv_model(is_training=True, dropout_rate=0.2)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "qn5QKEaWOhcE",
        "outputId": "e7931365-8d5d-48ad-afb2-7d4c75abb9a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"tiny_embedding_conv_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"tiny_embedding_conv_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input (\u001b[38;5;33mInputLayer\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1960\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape_3 (\u001b[38;5;33mReshape\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ first_conv (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m8\u001b[0m)           │             \u001b[38;5;34m648\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ first_relu (\u001b[38;5;33mReLU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m8\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ first_dropout (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m8\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ second_conv (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m8\u001b[0m)             │           \u001b[38;5;34m5,128\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ second_relu (\u001b[38;5;33mReLU\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m8\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ second_dropout (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m8\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ final_fc (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m388\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1960</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ first_conv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">648</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ first_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ first_dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ second_conv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,128</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ second_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ second_dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ final_fc (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">388</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,164\u001b[0m (24.08 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,164</span> (24.08 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,164\u001b[0m (24.08 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,164</span> (24.08 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_tiny_embedding_conv_model(is_training=True, dropout_rate = 0.2)\n",
        "model.summary()\n",
        "\n",
        "# You can then compile and train the model as usual:\n",
        "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "# model.fit(train_data, train_labels, epochs=10, validation_data=(val_data, val_labels))\n"
      ],
      "metadata": {
        "id": "T6hxiDVJrUxu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 860
        },
        "outputId": "19b7e35a-ee02-4d83-b1a3-43d70e3c2e84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "{{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 1 values, but the requested shape has 1960 [Op:Reshape]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-d0db4a8e6443>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_tiny_embedding_conv_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# You can then compile and train the model as usual:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-fc1c733ff300>\u001b[0m in \u001b[0;36mcreate_tiny_embedding_conv_model\u001b[0;34m(is_training, dropout_rate)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0minput_frequency_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m49\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0minput_time_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   fingerprint_4d = tf.reshape((1960, ),\n\u001b[0m\u001b[1;32m      8\u001b[0m                               [input_time_size, input_frequency_size, 1])\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 1 values, but the requested shape has 1960 [Op:Reshape]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.lite.python import schema_py_generated as schema\n",
        "\n",
        "def get_tflite_operations(tflite_model_path):\n",
        "    # Load the TFLite model file\n",
        "    with open(tflite_model_path, \"rb\") as f:\n",
        "        model_data = f.read()\n",
        "\n",
        "    # Parse the TFLite model\n",
        "    model = schema.Model.GetRootAsModel(model_data, 0)\n",
        "\n",
        "    # Get the subgraph (usually only one in most models)\n",
        "    subgraph = model.Subgraphs(0)\n",
        "    operators = subgraph.OperatorsLength()\n",
        "\n",
        "    # Extract all the operation codes used in the model\n",
        "    op_codes = []\n",
        "    for i in range(operators):\n",
        "        op_code_index = subgraph.Operators(i).OpcodeIndex()\n",
        "        op_code = model.OperatorCodes(op_code_index).BuiltinCode()\n",
        "        op_codes.append(op_code)\n",
        "\n",
        "    # Map operation codes to their names using BuiltinOperator.__dict__\n",
        "    op_names = [key for key, value in schema.BuiltinOperator.__dict__.items() if value in op_codes]\n",
        "    return set(op_names)  # Return unique operation names\n",
        "\n",
        "# Path to your TFLite model\n",
        "tflite_model_path = \"qat_sequential_23.tflite\"\n",
        "\n",
        "# Get and print operations\n",
        "operations = get_tflite_operations(tflite_model_path)\n",
        "print(\"Operations used in the TFLite model:\")\n",
        "for op in operations:\n",
        "    print(op)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVJJzR7zrU0V",
        "outputId": "a93a35a5-e384-41e7-c6d3-9530f0ff6bfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Operations used in the TFLite model:\n",
            "CONV_2D\n",
            "SHAPE\n",
            "PACK\n",
            "SOFTMAX\n",
            "QUANTIZE\n",
            "RESHAPE\n",
            "STRIDED_SLICE\n",
            "DEQUANTIZE\n",
            "FULLY_CONNECTED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ilv74gVquCOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Library for converting .tflite, .bmp and .wav files to cc arrays.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import struct\n",
        "import wave\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def generate_file(out_fname, array_name, array_type, array_contents, size):\n",
        "  \"\"\"Write an array of values to a CC or header file.\"\"\"\n",
        "  os.makedirs(os.path.dirname(out_fname), exist_ok=True)\n",
        "  if out_fname.endswith('.cc'):\n",
        "    out_cc_file = open(out_fname, 'w')\n",
        "    out_cc_file.write('#include <cstdint>\\n\\n')\n",
        "    out_cc_file.write('#include \"{}\"\\n\\n'.format(\n",
        "        out_fname.split('genfiles/')[-1].replace('.cc', '.h')))\n",
        "    out_cc_file.write('alignas(16) const {} {}[] = {{'.format(\n",
        "        array_type, array_name))\n",
        "    out_cc_file.write(array_contents)\n",
        "    out_cc_file.write('};\\n')\n",
        "    out_cc_file.close()\n",
        "  elif out_fname.endswith('.h'):\n",
        "    out_hdr_file = open(out_fname, 'w')\n",
        "    out_hdr_file.write('#include <cstdint>\\n\\n')\n",
        "    out_hdr_file.write('constexpr unsigned int {}_size = {};\\n'.format(\n",
        "        array_name, str(size)))\n",
        "    out_hdr_file.write('extern const {} {}[];\\n'.format(\n",
        "        array_type, array_name))\n",
        "    out_hdr_file.close()\n",
        "  else:\n",
        "    raise ValueError('generated file must be end with .cc or .h')\n",
        "\n",
        "\n",
        "def bytes_to_hexstring(buffer):\n",
        "  \"\"\"Convert a byte array to a hex string.\"\"\"\n",
        "  hex_values = [hex(buffer[i]) for i in range(len(buffer))]\n",
        "  out_string = ','.join(hex_values)\n",
        "  return out_string\n",
        "\n",
        "\n",
        "def generate_array(input_fname):\n",
        "  \"\"\"Return array size and array of data from the input file.\"\"\"\n",
        "  if input_fname.endswith('.tflite'):\n",
        "    with open(input_fname, 'rb') as input_file:\n",
        "      buffer = input_file.read()\n",
        "    size = len(buffer)\n",
        "    out_string = bytes_to_hexstring(buffer)\n",
        "    return [size, out_string]\n",
        "  elif input_fname.endswith('.bmp'):\n",
        "    img = Image.open(input_fname, mode='r')\n",
        "    image_bytes = img.tobytes()\n",
        "    size = len(image_bytes)\n",
        "    out_string = bytes_to_hexstring(image_bytes)\n",
        "    return [size, out_string]\n",
        "  elif input_fname.endswith('.wav'):\n",
        "    wav_file = wave.open(input_fname, mode='r')\n",
        "    num_channels = wav_file.getnchannels()\n",
        "    n_frames = wav_file.getnframes()\n",
        "    frames = wav_file.readframes(n_frames)\n",
        "    samples = struct.unpack('<%dh' % (num_channels * n_frames), frames)\n",
        "    out_string = ','.join(map(str, samples))\n",
        "    wav_file.close()\n",
        "    return [wav_file.getnframes(), out_string]\n",
        "  elif input_fname.endswith('.csv'):\n",
        "    with open(input_fname, 'r') as input_file:\n",
        "      # Assume one array per csv file.\n",
        "      elements = input_file.readline()\n",
        "      return [len(elements.split(',')), elements]\n",
        "  elif input_fname.endswith('.npy'):\n",
        "    data = np.float32(np.load(input_fname, allow_pickle=False))\n",
        "    data_1d = data.flatten()\n",
        "    out_string = ','.join([str(x) for x in data_1d])\n",
        "    return [len(data_1d), out_string]\n",
        "\n",
        "  else:\n",
        "    raise ValueError('input file must be .tflite, .bmp, .wav or .csv')\n",
        "\n",
        "\n",
        "def get_array_name(input_fname):\n",
        "  # Normalize potential relative path to remove additional dot.\n",
        "  abs_fname = os.path.abspath(input_fname)\n",
        "  base_array_name = 'g_' + abs_fname.split('.')[-2].split('/')[-1]\n",
        "  if input_fname.endswith('.tflite'):\n",
        "    return [base_array_name + '_model_data', 'unsigned char']\n",
        "  elif input_fname.endswith('.bmp'):\n",
        "    return [base_array_name + '_image_data', 'unsigned char']\n",
        "  elif input_fname.endswith('.wav'):\n",
        "    return [base_array_name + '_audio_data', 'int16_t']\n",
        "  elif input_fname.endswith('_int32.csv'):\n",
        "    return [base_array_name + '_test_data', 'int32_t']\n",
        "  elif input_fname.endswith('_int16.csv'):\n",
        "    return [base_array_name + '_test_data', 'int16_t']\n",
        "  elif input_fname.endswith('_int8.csv'):\n",
        "    return [base_array_name + '_test_data', 'int8_t']\n",
        "  elif input_fname.endswith('_float.csv'):\n",
        "    return [base_array_name + '_test_data', 'float']\n",
        "  elif input_fname.endswith('npy'):\n",
        "    return [base_array_name + '_test_data', 'float']\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zh0geIRenJ-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(output, inputs):\n",
        "    \"\"\"Create cc sources with c arrays with data from each .tflite or .bmp.\"\"\"\n",
        "    if output.endswith('.cc') or output.endswith('.h'):\n",
        "        assert len(inputs) == 1\n",
        "        size, cc_array = generate_array(inputs[0])\n",
        "        generated_array_name, array_type = get_array_name(inputs[0])\n",
        "        generate_file(output, generated_array_name, array_type, cc_array, size)\n",
        "    else:\n",
        "        # Deduplicate inputs to prevent duplicate generated files (ODR issue).\n",
        "        for input_file in list(dict.fromkeys(inputs)):\n",
        "            output_base_fname = os.path.join(output, os.path.splitext(input_file)[0])\n",
        "            if input_file.endswith('.tflite'):\n",
        "                output_base_fname += '_model_data'\n",
        "            elif input_file.endswith('.bmp'):\n",
        "                output_base_fname += '_image_data'\n",
        "            elif input_file.endswith('.wav'):\n",
        "                output_base_fname += '_audio_data'\n",
        "            elif input_file.endswith('.csv'):\n",
        "                output_base_fname += '_test_data'\n",
        "            elif input_file.endswith('.npy'):\n",
        "                output_base_fname += '_test_data'\n",
        "            else:\n",
        "                raise ValueError('Input file must be .tflite, .bmp, .wav, .npy, or .csv')\n",
        "\n",
        "            output_cc_fname = output_base_fname + '.cc'\n",
        "            print(\"Generated:\", output_cc_fname)  # For visibility in Colab output\n",
        "            output_hdr_fname = output_base_fname + '.h'\n",
        "            size, cc_array = generate_array(input_file)\n",
        "            generated_array_name, array_type = get_array_name(input_file)\n",
        "            generate_file(output_cc_fname, generated_array_name, array_type, cc_array, size)\n",
        "            generate_file(output_hdr_fname, generated_array_name, array_type, cc_array, size)\n"
      ],
      "metadata": {
        "id": "OSKA_EPQnKAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage in Colab:\n",
        "# Replace 'output_dir' and 'input_files' with your desired paths and files.\n",
        "output_dir = '/content/'\n",
        "input_files = ['audio_preprocessor_float.tflite']\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Run the main function\n",
        "main(output_dir, input_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "WAlemIGvogWM",
        "outputId": "bf540231-72be-4638-eb94-0cddfc0023b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated: /content/audio_preprocessor_float_model_data.cc\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'audio_preprocessor_float.tflite'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-8b7f42c5ad69>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Run the main function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-b92c085abab6>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(output, inputs)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Generated:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_cc_fname\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# For visibility in Colab output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0moutput_hdr_fname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_base_fname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.h'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mgenerated_array_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_array_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mgenerate_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_cc_fname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_array_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-f3758c874e56>\u001b[0m in \u001b[0;36mgenerate_array\u001b[0;34m(input_fname)\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;34m\"\"\"Return array size and array of data from the input file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minput_fname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.tflite'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m       \u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'audio_preprocessor_float.tflite'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q2qkUVilogyR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}