{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook with model definitions\n",
    "\n",
    "This notebook contains the definitions for the models and a py version of it will be used to import it to the training notebook\n",
    "on second thought we can use ipynb library to import directly to the jupyter notebook\n",
    "\n",
    "[model inspiration paper](https://www.isca-archive.org/interspeech_2015/sainath15b_interspeech.html)\n",
    "\n",
    "[model inspiration code from TF](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/speech_commands/models.py#L673)\n",
    "\n",
    "^^^ two OG papers that are definitelly good\n",
    "\n",
    "[general keywrod spotting on microcontroller paper](https://arxiv.org/abs/1711.07128)\n",
    "\n",
    "\n",
    "[binary quantization paper, might not be possible with tf and espressif](https://www.isca-archive.org/interspeech_2022/wang22g_interspeech.html)\n",
    "\n",
    "These two papers go into other possible model architecutes:\n",
    "\n",
    "[model with temporal convolutions](https://www.isca-archive.org/interspeech_2020/li20s_interspeech.html)\n",
    "\n",
    "[depthwise conv](https://www.isca-archive.org/interspeech_2020/xu20d_interspeech.html) this might be very good\n",
    "\n",
    "maybe for NAS:\n",
    "\n",
    "[micronets maybe for NAS](https://arxiv.org/abs/2010.11267)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\adamk\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "from IPython import display\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, GlobalAveragePooling2D, Dense, Activation, Input, Reshape, Multiply, AveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, ReLU, Dropout\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow_model_optimization.python.core.keras.compat import keras\n",
    "from keras.layers import Resizing\n",
    "from tensorflow_model_optimization.quantization.keras import quantize_annotate_layer\n",
    "import tempfile\n",
    "\n",
    "import keras_tuner as kt\n",
    "import nbimporter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is needed for layers that are not supported by the quantization API\n",
    "class NoOpQuantizeConfig(tfmot.quantization.keras.QuantizeConfig):\n",
    "    def get_weights_and_quantizers(self, layer):\n",
    "        return []\n",
    "\n",
    "    def get_activations_and_quantizers(self, layer):\n",
    "        return []\n",
    "\n",
    "    def set_quantize_weights(self, layer, quantize_weights):\n",
    "        pass\n",
    "\n",
    "    def set_quantize_activations(self, layer, quantize_activations):\n",
    "        pass\n",
    "\n",
    "    def get_output_quantizers(self, layer):\n",
    "        return []\n",
    "\n",
    "    def get_config(self):\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_1(input_shape, num_classes=6, is_training=True):\n",
    "    # Build the model step-by-step\n",
    "    model = keras.Sequential(name='CNN1')\n",
    "    \n",
    "    # Input layer\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    \n",
    "    # Quantize layer (assuming quantize_annotate_layer is correctly defined elsewhere)\n",
    "    model.add(quantize_annotate_layer(\n",
    "        keras.layers.Resizing(32, 32), \n",
    "        quantize_config=NoOpQuantizeConfig()\n",
    "    ))\n",
    "    \n",
    "    # Adding convolution, pooling, and dropout layers\n",
    "    model.add(keras.layers.Conv2D(32, 3, activation='relu'))\n",
    "    model.add(keras.layers.Conv2D(64, 3, activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D())\n",
    "    model.add(keras.layers.Dropout(0.25))\n",
    "    \n",
    "    # Flatten layer\n",
    "    model.add(keras.layers.Flatten())\n",
    "    \n",
    "    # Fully connected layers\n",
    "    model.add(keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(keras.layers.Dense(num_classes))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduced complexity for faster training and smaller size\n",
    "def create_model_2(input_shape, num_classes=6, is_training=True):\n",
    "    model = keras.Sequential(name='CNN2')\n",
    "\n",
    "    model.add(keras.layers.Input(shape=input_shape))\n",
    "\n",
    "    # Quantize layer (assuming quantize_annotate_layer is correctly defined elsewhere)\n",
    "    model.add(quantize_annotate_layer(\n",
    "        keras.layers.Resizing(32, 32), \n",
    "        quantize_config=NoOpQuantizeConfig()\n",
    "    ))\n",
    "    \n",
    "    # Normalize.\n",
    "    #norm_layer,\n",
    "    model.add(keras.layers.Conv2D(32, 3, activation='relu'))\n",
    "    #layers.Conv2D(64, 3, activation='relu'),\n",
    "    model.add(keras.layers.MaxPooling2D())\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.25))\n",
    "    model.add(keras.layers.Dense(num_classes))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 Tiny Conv model from paper \n",
    "\n",
    "These models are defined twice, once as from my interpretation of the paper models and once as tf.Sequencetial models to work with quantization aware training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef create_tiny_conv_model_small(input_shape, num_classes=6, is_training=True):\\n    \"\"\"\\n    Builds a tiny convolutional model optimized for microcontrollers.\\n\\n    Args:\\n        input_shape: Tuple, the shape of the input data (time_steps, frequency_bins, channels).\\n        num_classes: Integer, number of output classes.\\n        is_training: Boolean, whether the model is being trained or deployed.\\n\\n    Returns:\\n        model: Keras Model instance.\\n    \"\"\"\\n    inputs = Input(shape=(124, 129, 1), name=\\'input\\')\\n\\n    # Convolutional Layer\\n    x = Conv2D(filters=8,\\n               kernel_size=(10, 8),\\n               strides=(2, 2),\\n               padding=\\'same\\',\\n               use_bias=True,\\n               kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\\n               bias_initializer=\\'zeros\\',\\n               name=\\'conv\\')(inputs)\\n    \\n    # ReLU Activation\\n    x = ReLU(name=\\'relu1\\')(x)\\n    \\n    # Optional Dropout Layer\\n    if is_training:\\n        x = Dropout(rate=0.2, name=\\'dropout1\\')(x)\\n    \\n    # Flatten the output\\n    x = Flatten(name=\\'flatten\\')(x)\\n    \\n    # Output Layer\\n    outputs = Dense(units=num_classes,\\n                    activation=\\'softmax\\',  # Use \\'softmax\\' if you prefer probabilities\\n                    kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\\n                    bias_initializer=\\'zeros\\',\\n                    name=\\'fc2\\')(x)\\n    \\n    # Define the model\\n    model = Model(inputs=inputs, outputs=outputs, name=\\'tiny_conv_model\\')\\n    \\n    return model\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def create_tiny_conv_model_small(input_shape, num_classes=6, is_training=True):\n",
    "    \"\"\"\n",
    "    Builds a tiny convolutional model optimized for microcontrollers.\n",
    "\n",
    "    Args:\n",
    "        input_shape: Tuple, the shape of the input data (time_steps, frequency_bins, channels).\n",
    "        num_classes: Integer, number of output classes.\n",
    "        is_training: Boolean, whether the model is being trained or deployed.\n",
    "\n",
    "    Returns:\n",
    "        model: Keras Model instance.\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=(124, 129, 1), name='input')\n",
    "\n",
    "    # Convolutional Layer\n",
    "    x = Conv2D(filters=8,\n",
    "               kernel_size=(10, 8),\n",
    "               strides=(2, 2),\n",
    "               padding='same',\n",
    "               use_bias=True,\n",
    "               kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\n",
    "               bias_initializer='zeros',\n",
    "               name='conv')(inputs)\n",
    "    \n",
    "    # ReLU Activation\n",
    "    x = ReLU(name='relu1')(x)\n",
    "    \n",
    "    # Optional Dropout Layer\n",
    "    if is_training:\n",
    "        x = Dropout(rate=0.2, name='dropout1')(x)\n",
    "    \n",
    "    # Flatten the output\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    \n",
    "    # Output Layer\n",
    "    outputs = Dense(units=num_classes,\n",
    "                    activation='softmax',  # Use 'softmax' if you prefer probabilities\n",
    "                    kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\n",
    "                    bias_initializer='zeros',\n",
    "                    name='fc2')(x)\n",
    "    \n",
    "    # Define the model\n",
    "    model = Model(inputs=inputs, outputs=outputs, name='tiny_conv_model')\n",
    "    \n",
    "    return model\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tiny convolutional model using Sequential API\n",
    "def create_tiny_conv_model_small(input_shape=(124, 129, 1), num_classes=6, is_training=True):\n",
    "    model = keras.Sequential(name='tiny_conv_model')\n",
    "    model.add(keras.layers.Conv2D(filters=8,\n",
    "                     kernel_size=(10, 8),\n",
    "                     strides=(2, 2),\n",
    "                     padding='same',\n",
    "                     use_bias=True,\n",
    "                     kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\n",
    "                     bias_initializer='zeros',\n",
    "                     input_shape=input_shape,\n",
    "                     name='conv'))\n",
    "    model.add(keras.layers.ReLU(name='relu1'))\n",
    "    \n",
    "    if is_training:\n",
    "        model.add(keras.layers.Dropout(rate=0.2, name='dropout1'))\n",
    "    \n",
    "    model.add(keras.layers.Flatten(name='flatten'))\n",
    "    \n",
    "    model.add(keras.layers.Dense(units=num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\n",
    "                    bias_initializer='zeros',\n",
    "                    name='fc2'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4 Tiny Embed Conv model from paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef create_tiny_embed_conv_model_small(input_shape, num_classes=6, is_training=True):\\n    \"\"\"\\n    Builds a tiny convolutional model optimized for microcontrollers.\\n\\n    Args:\\n        input_shape: Tuple, the shape of the input data (time_steps, frequency_bins, channels).\\n        num_classes: Integer, number of output classes.\\n        is_training: Boolean, whether the model is being trained or deployed.\\n\\n    Returns:\\n        model: Keras Model instance.\\n    \"\"\"\\n    inputs = Input(shape=(124, 129, 1), name=\\'input\\')\\n\\n    # Convolutional Layer\\n    x = Conv2D(filters=8,\\n               kernel_size=(10, 8),\\n               strides=(2, 2),\\n               padding=\\'same\\',\\n               use_bias=True,\\n               kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\\n               bias_initializer=\\'zeros\\',\\n               name=\\'conv1\\')(inputs)\\n    \\n    # ReLU Activation\\n    x = ReLU(name=\\'relu1\\')(x)\\n    \\n    # Optional Dropout Layer\\n    if is_training:\\n        x = Dropout(rate=0.2, name=\\'dropout1\\')(x)\\n\\n    # Convolutional Layer\\n    x = Conv2D(filters=8,\\n               kernel_size=(10, 8),\\n               strides=(8, 8),\\n               padding=\\'same\\',\\n               use_bias=True,\\n               kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\\n               bias_initializer=\\'zeros\\',\\n               name=\\'conv2\\')(x)\\n    \\n    # ReLU Activation\\n    x = ReLU(name=\\'relu2\\')(x)\\n    \\n    # Optional Dropout Layer\\n    if is_training:\\n        x = Dropout(rate=0.2, name=\\'dropout2\\')(x)\\n    \\n    # Flatten the output\\n    x = Flatten(name=\\'flatten\\')(x)\\n    \\n    # Output Layer\\n    outputs = Dense(units=num_classes,\\n                    activation=\\'softmax\\',  # Use \\'softmax\\' if you prefer probabilities\\n                    kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\\n                    bias_initializer=\\'zeros\\',\\n                    name=\\'fc2\\')(x)\\n    \\n    # Define the model\\n    model = Model(inputs=inputs, outputs=outputs, name=\\'tiny_embed_conv_model\\')\\n    \\n    return model\\n    \\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def create_tiny_embed_conv_model_small(input_shape, num_classes=6, is_training=True):\n",
    "    \"\"\"\n",
    "    Builds a tiny convolutional model optimized for microcontrollers.\n",
    "\n",
    "    Args:\n",
    "        input_shape: Tuple, the shape of the input data (time_steps, frequency_bins, channels).\n",
    "        num_classes: Integer, number of output classes.\n",
    "        is_training: Boolean, whether the model is being trained or deployed.\n",
    "\n",
    "    Returns:\n",
    "        model: Keras Model instance.\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=(124, 129, 1), name='input')\n",
    "\n",
    "    # Convolutional Layer\n",
    "    x = Conv2D(filters=8,\n",
    "               kernel_size=(10, 8),\n",
    "               strides=(2, 2),\n",
    "               padding='same',\n",
    "               use_bias=True,\n",
    "               kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\n",
    "               bias_initializer='zeros',\n",
    "               name='conv1')(inputs)\n",
    "    \n",
    "    # ReLU Activation\n",
    "    x = ReLU(name='relu1')(x)\n",
    "    \n",
    "    # Optional Dropout Layer\n",
    "    if is_training:\n",
    "        x = Dropout(rate=0.2, name='dropout1')(x)\n",
    "\n",
    "    # Convolutional Layer\n",
    "    x = Conv2D(filters=8,\n",
    "               kernel_size=(10, 8),\n",
    "               strides=(8, 8),\n",
    "               padding='same',\n",
    "               use_bias=True,\n",
    "               kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\n",
    "               bias_initializer='zeros',\n",
    "               name='conv2')(x)\n",
    "    \n",
    "    # ReLU Activation\n",
    "    x = ReLU(name='relu2')(x)\n",
    "    \n",
    "    # Optional Dropout Layer\n",
    "    if is_training:\n",
    "        x = Dropout(rate=0.2, name='dropout2')(x)\n",
    "    \n",
    "    # Flatten the output\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    \n",
    "    # Output Layer\n",
    "    outputs = Dense(units=num_classes,\n",
    "                    activation='softmax',  # Use 'softmax' if you prefer probabilities\n",
    "                    kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\n",
    "                    bias_initializer='zeros',\n",
    "                    name='fc2')(x)\n",
    "    \n",
    "    # Define the model\n",
    "    model = Model(inputs=inputs, outputs=outputs, name='tiny_embed_conv_model')\n",
    "    \n",
    "    return model\n",
    "    \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tiny embedded convolutional model using Sequential API\n",
    "def create_tiny_embed_conv_model_small(input_shape=(124, 129, 1), num_classes=6, is_training=True):\n",
    "    model = keras.Sequential(name='tiny_embed_conv_model')\n",
    "    model.add(keras.layers.Conv2D(filters=8,\n",
    "                     kernel_size=(10, 8),\n",
    "                     strides=(2, 2),\n",
    "                     padding='same',\n",
    "                     use_bias=True,\n",
    "                     kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\n",
    "                     bias_initializer='zeros',\n",
    "                     input_shape=input_shape,\n",
    "                     name='conv1'))\n",
    "    model.add(keras.layers.ReLU(name='relu1'))\n",
    "    \n",
    "    if is_training:\n",
    "        model.add(keras.layers.Dropout(rate=0.2, name='dropout1'))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(filters=8,\n",
    "                     kernel_size=(10, 8),\n",
    "                     strides=(8, 8),\n",
    "                     padding='same',\n",
    "                     use_bias=True,\n",
    "                     kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\n",
    "                     bias_initializer='zeros',\n",
    "                     name='conv2'))\n",
    "    model.add(keras.layers.ReLU(name = 'relu2'))\n",
    "    \n",
    "    if is_training:\n",
    "        model.add(keras.layers.Dropout(rate=0.2, name='dropout2'))\n",
    "    \n",
    "    model.add(keras.layers.Flatten(name='flatten'))\n",
    "    model.add(keras.layers.Dense(units=num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\n",
    "                    bias_initializer='zeros',\n",
    "                    name='fc2'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5 the tiny embed conv model with hyperparameters after gridsearching hypterparameters\n",
    "\n",
    "Best hyperparameters: {'kernel_size_1_height': 9, 'kernel_size_1_width': 9, 'stride_1_height': 2, 'stride_1_width': 1, 'conv1_filters': 16, 'dropout_1': True, 'kernel_size_2_height': 7, 'kernel_size_2_width': 7, 'stride_2_height': 4, 'stride_2_width': 6, 'conv2_filters': 12, 'dropout_2': True, 'tuner/epochs': 15, 'tuner/initial_epoch': 5, 'tuner/bracket': 2, 'tuner/round': 2, 'tuner/trial_id': '0013'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef create_tiny_embed_conv_model_small_best(input_shape, num_classes=6, is_training=True):\\n    \"\"\"\\n    Builds a tiny convolutional model optimized for microcontrollers.\\n\\n    Args:\\n        input_shape: Tuple, the shape of the input data (time_steps, frequency_bins, channels).\\n        num_classes: Integer, number of output classes.\\n        is_training: Boolean, whether the model is being trained or deployed.\\n\\n    Returns:\\n        model: Keras Model instance.\\n    \"\"\"\\n    inputs = Input(shape=(124, 129, 1), name=\\'input\\')\\n\\n    # Convolutional Layer\\n    x = Conv2D(filters=16,\\n               kernel_size=(9, 9),\\n               strides=(2, 1),\\n               padding=\\'same\\',\\n               use_bias=True,\\n               kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\\n               bias_initializer=\\'zeros\\',\\n               name=\\'conv1\\')(inputs)\\n    \\n    # ReLU Activation\\n    x = ReLU(name=\\'relu1\\')(x)\\n    \\n    # Optional Dropout Layer\\n    if is_training:\\n        x = Dropout(rate=0.2, name=\\'dropout1\\')(x)\\n\\n    # Convolutional Layer\\n    x = Conv2D(filters=12,\\n               kernel_size=(7, 7),\\n               strides=(4, 6),\\n               padding=\\'same\\',\\n               use_bias=True,\\n               kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\\n               bias_initializer=\\'zeros\\',\\n               name=\\'conv2\\')(x)\\n    \\n    # ReLU Activation\\n    x = ReLU(name=\\'relu2\\')(x)\\n    \\n    # Optional Dropout Layer\\n    if is_training:\\n        x = Dropout(rate=0.2, name=\\'dropout2\\')(x)\\n    \\n    # Flatten the output\\n    x = Flatten(name=\\'flatten\\')(x)\\n    \\n    # Output Layer\\n    outputs = Dense(units=num_classes,\\n                    activation=\\'softmax\\',  # Use \\'softmax\\' if you prefer probabilities\\n                    kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\\n                    bias_initializer=\\'zeros\\',\\n                    name=\\'fc2\\')(x)\\n    \\n    # Define the model\\n    model = Model(inputs=inputs, outputs=outputs, name=\\'tiny_embed_conv_model_best\\')\\n    \\n    return model\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def create_tiny_embed_conv_model_small_best(input_shape, num_classes=6, is_training=True):\n",
    "    \"\"\"\n",
    "    Builds a tiny convolutional model optimized for microcontrollers.\n",
    "\n",
    "    Args:\n",
    "        input_shape: Tuple, the shape of the input data (time_steps, frequency_bins, channels).\n",
    "        num_classes: Integer, number of output classes.\n",
    "        is_training: Boolean, whether the model is being trained or deployed.\n",
    "\n",
    "    Returns:\n",
    "        model: Keras Model instance.\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=(124, 129, 1), name='input')\n",
    "\n",
    "    # Convolutional Layer\n",
    "    x = Conv2D(filters=16,\n",
    "               kernel_size=(9, 9),\n",
    "               strides=(2, 1),\n",
    "               padding='same',\n",
    "               use_bias=True,\n",
    "               kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\n",
    "               bias_initializer='zeros',\n",
    "               name='conv1')(inputs)\n",
    "    \n",
    "    # ReLU Activation\n",
    "    x = ReLU(name='relu1')(x)\n",
    "    \n",
    "    # Optional Dropout Layer\n",
    "    if is_training:\n",
    "        x = Dropout(rate=0.2, name='dropout1')(x)\n",
    "\n",
    "    # Convolutional Layer\n",
    "    x = Conv2D(filters=12,\n",
    "               kernel_size=(7, 7),\n",
    "               strides=(4, 6),\n",
    "               padding='same',\n",
    "               use_bias=True,\n",
    "               kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\n",
    "               bias_initializer='zeros',\n",
    "               name='conv2')(x)\n",
    "    \n",
    "    # ReLU Activation\n",
    "    x = ReLU(name='relu2')(x)\n",
    "    \n",
    "    # Optional Dropout Layer\n",
    "    if is_training:\n",
    "        x = Dropout(rate=0.2, name='dropout2')(x)\n",
    "    \n",
    "    # Flatten the output\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    \n",
    "    # Output Layer\n",
    "    outputs = Dense(units=num_classes,\n",
    "                    activation='softmax',  # Use 'softmax' if you prefer probabilities\n",
    "                    kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\n",
    "                    bias_initializer='zeros',\n",
    "                    name='fc2')(x)\n",
    "    \n",
    "    # Define the model\n",
    "    model = Model(inputs=inputs, outputs=outputs, name='tiny_embed_conv_model_best')\n",
    "    \n",
    "    return model\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tiny embedded convolutional model (best version) using Sequential API\n",
    "def create_tiny_embed_conv_model_small_best(input_shape=(124, 129, 1), num_classes=6, is_training=True):\n",
    "    model = keras.Sequential(name='tiny_embed_conv_model_best')\n",
    "    model.add(keras.layers.Conv2D(filters=16,\n",
    "                     kernel_size=(9, 9),\n",
    "                     strides=(2, 1),\n",
    "                     padding='same',\n",
    "                     use_bias=True,\n",
    "                     kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\n",
    "                     bias_initializer='zeros',\n",
    "                     input_shape=input_shape,\n",
    "                     name='conv1'))\n",
    "    model.add(keras.layers.ReLU(name='relu1'))\n",
    "    \n",
    "    if is_training:\n",
    "        model.add(keras.layers.Dropout(rate=0.2, name='dropout1'))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(filters=12,\n",
    "                     kernel_size=(7, 7),\n",
    "                     strides=(4, 6),\n",
    "                     padding='same',\n",
    "                     use_bias=True,\n",
    "                     kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\n",
    "                     bias_initializer='zeros',\n",
    "                     name='conv2'))\n",
    "    model.add(keras.layers.ReLU(name='relu2'))\n",
    "    \n",
    "    if is_training:\n",
    "        model.add(keras.layers.Dropout(rate=0.2, name='dropout2'))\n",
    "    \n",
    "    model.add(keras.layers.Flatten(name='flatten'))\n",
    "    model.add(keras.layers.Dense(units=num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),\n",
    "                    bias_initializer='zeros',\n",
    "                    name='fc2'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning (grid search)\n",
    "\n",
    "we can try to implement some sort of neural architecure search too (NAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    input_shape = (124, 129, 1)\n",
    "    num_classes = 6\n",
    "    \n",
    "    inputs = Input(shape=input_shape, name='input')\n",
    "\n",
    "    # First convolutional layer\n",
    "    kernel_size_1 = (hp.Int('kernel_size_1_height', min_value=3, max_value=10, step=2), \n",
    "                     hp.Int('kernel_size_1_width', min_value=3, max_value=10, step=2))\n",
    "    stride_1 = (hp.Int('stride_1_height', min_value=1, max_value=2, step=1), \n",
    "                hp.Int('stride_1_width', min_value=1, max_value=2, step=1))\n",
    "    \n",
    "    x = Conv2D(filters=hp.Int('conv1_filters', min_value=4, max_value=16, step=4),\n",
    "               kernel_size=kernel_size_1,\n",
    "               strides=stride_1,\n",
    "               padding='same',\n",
    "               use_bias=True,\n",
    "               name='conv1')(inputs)\n",
    "    \n",
    "    x = ReLU(name='relu1')(x)\n",
    "    \n",
    "    if hp.Boolean('dropout_1'):\n",
    "        x = Dropout(rate=0.2, name='dropout1')(x)\n",
    "\n",
    "    # Second convolutional layer\n",
    "    kernel_size_2 = (hp.Int('kernel_size_2_height', min_value=3, max_value=10, step=2), \n",
    "                     hp.Int('kernel_size_2_width', min_value=3, max_value=10, step=2))\n",
    "    stride_2 = (hp.Int('stride_2_height', min_value=4, max_value=8, step=2), \n",
    "                hp.Int('stride_2_width', min_value=4, max_value=8, step=2))\n",
    "    \n",
    "    x = Conv2D(filters=hp.Int('conv2_filters', min_value=4, max_value=16, step=4),\n",
    "               kernel_size=kernel_size_2,\n",
    "               strides=stride_2,\n",
    "               padding='same',\n",
    "               use_bias=True,\n",
    "               name='conv2')(x)\n",
    "    \n",
    "    x = ReLU(name='relu2')(x)\n",
    "    \n",
    "    if hp.Boolean('dropout_2'):\n",
    "        x = Dropout(rate=0.2, name='dropout2')(x)\n",
    "    \n",
    "    # Flatten\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = Dense(units=num_classes, activation='softmax', name='fc2')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "if gridsearch == True:\n",
    "    # Initialize the tuner\n",
    "    tuner = kt.Hyperband(build_model,\n",
    "                        objective='val_accuracy',\n",
    "                        max_epochs=15,\n",
    "                        factor=3,\n",
    "                        directory='hyperparameter_tuning_tests',\n",
    "                        project_name='hyperparameter_tuning')\n",
    "\n",
    "    # Perform the search\n",
    "    tuner.search(train_spectrogram_ds, validation_data=val_spectrogram_ds, epochs=10)\n",
    "\n",
    "    # Get the best model\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "    best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "    print(f\"Best hyperparameters: {best_hp.values}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot training history (accuracy and loss)\n",
    "def plot_training_history(history, model_number):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs_range = range(len(acc))\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title(f'Model {model_number} - Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(f'Model {model_number} - Training and Validation Loss')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
