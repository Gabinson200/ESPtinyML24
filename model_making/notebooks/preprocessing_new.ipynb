{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f78fd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from typing import List, Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da352667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature parameters class\n",
    "class FeatureParams:\n",
    "    def __init__(self, sample_rate, window_size_ms, window_stride_ms, num_mel_bins, lower_frequency, upper_frequency, clip_duration_ms):\n",
    "        self.sample_rate = sample_rate\n",
    "        self.window_size_ms = window_size_ms\n",
    "        self.window_stride_ms = window_stride_ms\n",
    "        self.num_mel_bins = num_mel_bins\n",
    "        self.lower_frequency = lower_frequency\n",
    "        self.upper_frequency = upper_frequency\n",
    "        self.clip_duration_ms = clip_duration_ms\n",
    "        self.desired_samples = int(sample_rate * (clip_duration_ms / 1000.0))\n",
    "        self.window_length_samples = int(sample_rate * (window_size_ms / 1000.0))\n",
    "        self.window_step_samples = int(sample_rate * (window_stride_ms / 1000.0))\n",
    "        self.fft_length = 2 ** int(np.ceil(np.log2(self.window_length_samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e97af39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio processor class\n",
    "class AudioProcessor:\n",
    "    def __init__(self, params: FeatureParams):\n",
    "        self.params = params\n",
    "\n",
    "    def load_wav_file(self, filename: str) -> tf.Tensor:\n",
    "        audio_binary = tf.io.read_file(filename)\n",
    "        waveform, _ = tf.audio.decode_wav(audio_binary, desired_channels=1)\n",
    "        waveform = tf.squeeze(waveform, axis=-1)\n",
    "        waveform = waveform[:self.params.desired_samples]\n",
    "        zero_padding = tf.zeros(\n",
    "            [self.params.desired_samples - tf.shape(waveform)[0]], dtype=tf.float32\n",
    "        )\n",
    "        waveform = tf.concat([waveform, zero_padding], 0)\n",
    "        return waveform\n",
    "\n",
    "    def process_waveform(self, waveform: tf.Tensor) -> tf.Tensor:\n",
    "        frames = tf.signal.frame(\n",
    "            waveform,\n",
    "            self.params.window_length_samples,\n",
    "            self.params.window_step_samples,\n",
    "            pad_end=True,\n",
    "        )\n",
    "        window = tf.signal.hann_window(self.params.window_length_samples)\n",
    "        windowed_frames = frames * window\n",
    "        fft = tf.signal.rfft(windowed_frames, [self.params.fft_length])\n",
    "        power_spectrum = tf.abs(fft) ** 2\n",
    "        num_spectrogram_bins = self.params.fft_length // 2 + 1\n",
    "        linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
    "            self.params.num_mel_bins,\n",
    "            num_spectrogram_bins,\n",
    "            self.params.sample_rate,\n",
    "            self.params.lower_frequency,\n",
    "            self.params.upper_frequency,\n",
    "        )\n",
    "        mel_spectrogram = tf.tensordot(power_spectrum, linear_to_mel_weight_matrix, 1)\n",
    "        mel_spectrogram.set_shape(\n",
    "            power_spectrum.shape[:-1].concatenate([self.params.num_mel_bins])\n",
    "        )\n",
    "        log_mel_spectrogram = tf.math.log(mel_spectrogram + 1e-6)\n",
    "\n",
    "        expected_num_frames = (\n",
    "            1\n",
    "            + (self.params.desired_samples - self.params.window_length_samples)\n",
    "            // self.params.window_step_samples\n",
    "        )\n",
    "        num_frames = tf.shape(log_mel_spectrogram)[0]\n",
    "        num_padding_frames = expected_num_frames - num_frames\n",
    "        num_padding_frames = tf.maximum(num_padding_frames, 0)\n",
    "        log_mel_spectrogram = tf.pad(\n",
    "            log_mel_spectrogram, [[0, num_padding_frames], [0, 0]], \"CONSTANT\"\n",
    "        )\n",
    "        log_mel_spectrogram = log_mel_spectrogram[:expected_num_frames, :]\n",
    "        return log_mel_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9872c19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_background_noises(background_dir: str, params: FeatureParams) -> List[tf.Tensor]:\n",
    "    processor = AudioProcessor(params)\n",
    "    noise_chunks = []\n",
    "    for filename in os.listdir(background_dir):\n",
    "        if filename.endswith(\".wav\"):\n",
    "            background_file = os.path.join(background_dir, filename)\n",
    "            waveform = processor.load_wav_file(background_file)\n",
    "            chunk_size = params.desired_samples\n",
    "            total_samples = tf.shape(waveform)[0]\n",
    "            num_chunks = int(total_samples // chunk_size)\n",
    "            for i in range(num_chunks):\n",
    "                start_idx = i * chunk_size\n",
    "                end_idx = start_idx + chunk_size\n",
    "                chunk = waveform[start_idx:end_idx]\n",
    "                noise_chunks.append(chunk)\n",
    "    return noise_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f88059e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_background_noise(waveform: tf.Tensor, noise: tf.Tensor, desired_snr_db: float) -> tf.Tensor:\n",
    "    noise_power = tf.reduce_mean(noise ** 2)\n",
    "    signal_power = tf.reduce_mean(waveform ** 2)\n",
    "    snr_ratio = tf.pow(10.0, desired_snr_db / 10.0)\n",
    "    scaling_factor = tf.sqrt(signal_power / (snr_ratio * noise_power))\n",
    "    noisy_waveform = waveform + scaling_factor * noise\n",
    "    return tf.clip_by_value(noisy_waveform, -1.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "297ac43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_label(label, label_dir, processor, background_noises, params, output_dir, batch_size, batch_count):\n",
    "    label_to_index = {\"yes\": 0, \"no\": 1, \"background_noises\": 2}\n",
    "    if label not in label_to_index:\n",
    "        raise ValueError(f\"Label '{label}' not found in label_to_index mapping.\")\n",
    "    label_index = label_to_index[label]\n",
    "    print(f\"Processing label: {label}, label_index: {label_index}\")\n",
    "    batch_data = []\n",
    "    batch_labels = []\n",
    "\n",
    "    if label == \"background_noises\":\n",
    "        for noise in background_noises:\n",
    "            features = processor.process_waveform(noise)\n",
    "            batch_data.append(features.numpy())\n",
    "            batch_labels.append(label_index)\n",
    "            if len(batch_data) >= batch_size:\n",
    "                save_batch_to_disk(batch_data, batch_labels, output_dir, batch_count, label)\n",
    "                batch_data, batch_labels = [], []\n",
    "                batch_count += 1\n",
    "        if batch_data:\n",
    "            save_batch_to_disk(batch_data, batch_labels, output_dir, batch_count, label)\n",
    "            batch_data, batch_labels = [], []\n",
    "            batch_count += 1     \n",
    "            \n",
    "    else:\n",
    "        for filename in os.listdir(label_dir):\n",
    "            if filename.endswith(\".wav\"):\n",
    "                filepath = os.path.join(label_dir, filename)\n",
    "                waveform = processor.load_wav_file(filepath)\n",
    "                features = processor.process_waveform(waveform)\n",
    "                batch_data.append(features.numpy())\n",
    "                batch_labels.append(label_index)\n",
    "\n",
    "                for noise in background_noises:\n",
    "                    augmented_waveform = add_background_noise(waveform, noise, desired_snr_db=20)\n",
    "                    augmented_features = processor.process_waveform(augmented_waveform)\n",
    "                    batch_data.append(augmented_features.numpy())\n",
    "                    batch_labels.append(label_index)\n",
    "\n",
    "                if len(batch_data) >= batch_size:\n",
    "                    save_batch_to_disk(batch_data, batch_labels, output_dir, batch_count, label)\n",
    "                    batch_data, batch_labels = [], []\n",
    "                    batch_count += 1\n",
    "        pass\n",
    "\n",
    "    if batch_data:\n",
    "        save_batch_to_disk(batch_data, batch_labels, output_dir, batch_count, label)\n",
    "        batch_count += 1  # Increment after saving\n",
    "\n",
    "    return batch_count  # Return the updated batch_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43302de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_batch_to_disk(batch_data, batch_labels, output_dir, batch_count, label):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    np.save(os.path.join(output_dir, f\"{label}_batch_{batch_count}_features.npy\"), np.array(batch_data))\n",
    "    np.save(os.path.join(output_dir, f\"{label}_batch_{batch_count}_labels.npy\"), np.array(batch_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d08fa53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_batches(output_dir, final_features_file, final_labels_file):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Get lists of feature and label files\n",
    "    feature_files = sorted([f for f in os.listdir(output_dir) if 'features' in f])\n",
    "    label_files = sorted([f for f in os.listdir(output_dir) if 'labels' in f])\n",
    "\n",
    "    # Ensure the lists are sorted and matched\n",
    "    if len(feature_files) != len(label_files):\n",
    "        raise ValueError(\"Number of feature files and label files do not match.\")\n",
    "\n",
    "    for feature_file, label_file in zip(feature_files, label_files):\n",
    "        features = np.load(os.path.join(output_dir, feature_file))\n",
    "        labels = np.load(os.path.join(output_dir, label_file))\n",
    "        all_features.append(features)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    all_features = np.concatenate(all_features, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    np.save(os.path.join(output_dir, final_features_file), all_features)\n",
    "    np.save(os.path.join(output_dir, final_labels_file), all_labels)\n",
    "    print(f\"Combined features shape: {all_features.shape}\")\n",
    "    print(f\"Combined labels shape: {all_labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b614c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found label directory: no\n",
      "Processing label: no, label_index: 1\n",
      "Found label directory: background_noises\n",
      "Processing label: background_noises, label_index: 2\n",
      "Found label directory: yes\n",
      "Processing label: yes, label_index: 0\n"
     ]
    }
   ],
   "source": [
    "# Main processing\n",
    "data_dir = \"dataset_small\"\n",
    "background_file = os.path.join(data_dir, \"background_noises\", \"white_noise.wav\")\n",
    "output_dir = \"processed_dataset_small\"\n",
    "batch_size = 50\n",
    "\n",
    "params = FeatureParams(\n",
    "    sample_rate=16000,\n",
    "    window_size_ms=30.0,\n",
    "    window_stride_ms=20.0,\n",
    "    num_mel_bins=40,\n",
    "    lower_frequency=125.0,\n",
    "    upper_frequency=7500.0,\n",
    "    clip_duration_ms=1000.0\n",
    ")\n",
    "background_noises = split_background_noises(os.path.join(data_dir, \"background_noises\"), params)\n",
    "processor = AudioProcessor(params)\n",
    "\n",
    "batch_count = 0  # Initialize batch_count\n",
    "for label in os.listdir(data_dir):\n",
    "    if label.startswith('.'):\n",
    "        continue\n",
    "    print(f\"Found label directory: {label}\")\n",
    "    label_dir = os.path.join(data_dir, label)\n",
    "    if not os.path.isdir(label_dir):\n",
    "        continue\n",
    "    batch_count = process_and_save_label(label, label_dir, processor, background_noises, params, output_dir, batch_size, batch_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38a8dae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined features shape: (79961, 49, 40)\n",
      "Combined labels shape: (79961,)\n"
     ]
    }
   ],
   "source": [
    "combine_batches(output_dir, \"features.npy\", \"labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e672caed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Labels and Counts:\n",
      "Label: 0, Count: 44484\n",
      "Label: 1, Count: 35469\n",
      "Label: 2, Count: 8\n",
      "\n",
      "Labels Mapped to Names:\n",
      "Label: yes, Count: 44484\n",
      "Label: no, Count: 35469\n",
      "Label: background_noises, Count: 8\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"processed_dataset_small\"\n",
    "labels_file = os.path.join(output_dir, \"labels.npy\")\n",
    "\n",
    "labels = np.load(labels_file)\n",
    "\n",
    "unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "print(\"Unique Labels and Counts:\")\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    print(f\"Label: {label}, Count: {count}\")\n",
    "\n",
    "label_to_name = {0: \"yes\", 1: \"no\", 2: \"background_noises\"}\n",
    "named_labels = [label_to_name[label] for label in unique_labels]\n",
    "print(\"\\nLabels Mapped to Names:\")\n",
    "for name, count in zip(named_labels, counts):\n",
    "    print(f\"Label: {name}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66002e92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
