{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2db7517d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from typing import List, Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91f56ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature parameters class\n",
    "class FeatureParams:\n",
    "    def __init__(self, sample_rate, window_size_ms, window_stride_ms, num_mel_bins, lower_frequency, upper_frequency, clip_duration_ms):\n",
    "        self.sample_rate = sample_rate\n",
    "        self.window_size_ms = window_size_ms\n",
    "        self.window_stride_ms = window_stride_ms\n",
    "        self.num_mel_bins = num_mel_bins\n",
    "        self.lower_frequency = lower_frequency\n",
    "        self.upper_frequency = upper_frequency\n",
    "        self.clip_duration_ms = clip_duration_ms\n",
    "        self.desired_samples = int(sample_rate * (clip_duration_ms / 1000.0))\n",
    "        self.window_length_samples = int(sample_rate * (window_size_ms / 1000.0))\n",
    "        self.window_step_samples = int(sample_rate * (window_stride_ms / 1000.0))\n",
    "        self.fft_length = 2 ** int(np.ceil(np.log2(self.window_length_samples)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af5d8f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio processor class\n",
    "class AudioProcessor:\n",
    "    def __init__(self, params: FeatureParams):\n",
    "        self.params = params\n",
    "\n",
    "    def load_wav_file(self, filename: str) -> tf.Tensor:\n",
    "        audio_binary = tf.io.read_file(filename)\n",
    "        waveform, _ = tf.audio.decode_wav(audio_binary, desired_channels=1)\n",
    "        waveform = tf.squeeze(waveform, axis=-1)\n",
    "        return waveform\n",
    "\n",
    "    def process_waveform(self, waveform: tf.Tensor) -> tf.Tensor:\n",
    "        waveform = waveform[:self.params.desired_samples]\n",
    "        zero_padding = tf.zeros(\n",
    "            [self.params.desired_samples - tf.shape(waveform)[0]], dtype=tf.float32\n",
    "        )\n",
    "        waveform = tf.concat([waveform, zero_padding], 0)\n",
    "        frames = tf.signal.frame(\n",
    "            waveform,\n",
    "            self.params.window_length_samples,\n",
    "            self.params.window_step_samples,\n",
    "            pad_end=True,\n",
    "        )\n",
    "        window = tf.signal.hann_window(self.params.window_length_samples)\n",
    "        windowed_frames = frames * window\n",
    "        fft = tf.signal.rfft(windowed_frames, [self.params.fft_length])\n",
    "        power_spectrum = tf.abs(fft) ** 2\n",
    "        num_spectrogram_bins = self.params.fft_length // 2 + 1\n",
    "        linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
    "            self.params.num_mel_bins,\n",
    "            num_spectrogram_bins,\n",
    "            self.params.sample_rate,\n",
    "            self.params.lower_frequency,\n",
    "            self.params.upper_frequency,\n",
    "        )\n",
    "        mel_spectrogram = tf.tensordot(power_spectrum, linear_to_mel_weight_matrix, 1)\n",
    "        mel_spectrogram.set_shape(\n",
    "            power_spectrum.shape[:-1].concatenate([self.params.num_mel_bins])\n",
    "        )\n",
    "        log_mel_spectrogram = tf.math.log(mel_spectrogram + 1e-6)\n",
    "\n",
    "        expected_num_frames = (\n",
    "            1\n",
    "            + (self.params.desired_samples - self.params.window_length_samples)\n",
    "            // self.params.window_step_samples\n",
    "        )\n",
    "        num_frames = tf.shape(log_mel_spectrogram)[0]\n",
    "        num_padding_frames = expected_num_frames - num_frames\n",
    "        num_padding_frames = tf.maximum(num_padding_frames, 0)\n",
    "        log_mel_spectrogram = tf.pad(\n",
    "            log_mel_spectrogram, [[0, num_padding_frames], [0, 0]], \"CONSTANT\"\n",
    "        )\n",
    "        log_mel_spectrogram = log_mel_spectrogram[:expected_num_frames, :]\n",
    "        return log_mel_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "626c5a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_background_noises(background_dir: str, params: FeatureParams) -> List[tf.Tensor]:\n",
    "    processor = AudioProcessor(params)\n",
    "    background_noises = []\n",
    "    for filename in os.listdir(background_dir):\n",
    "        if filename.endswith(\".wav\"):\n",
    "            background_file = os.path.join(background_dir, filename)\n",
    "            waveform = processor.load_wav_file(background_file)\n",
    "            background_noises.append(waveform)\n",
    "    return background_noises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "482dc653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_chunks(noise_waveforms: List[tf.Tensor], params: FeatureParams, num_samples: int) -> Generator[tf.Tensor, None, None]:\n",
    "    for _ in range(num_samples):\n",
    "        # Randomly select a noise waveform\n",
    "        noise_waveform = random.choice(noise_waveforms)\n",
    "        total_samples = tf.shape(noise_waveform)[0]\n",
    "        if total_samples <= params.desired_samples:\n",
    "            chunk = noise_waveform\n",
    "        else:\n",
    "            max_start = total_samples - params.desired_samples\n",
    "            start_idx = tf.random.uniform([], 0, max_start, dtype=tf.int32)\n",
    "            chunk = noise_waveform[start_idx:start_idx + params.desired_samples]\n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20ffcef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_background_noise(waveform: tf.Tensor, noise: tf.Tensor, desired_snr_db: float) -> tf.Tensor:\n",
    "    # Both waveform and noise should already be the same length\n",
    "    noise_power = tf.reduce_mean(noise ** 2)\n",
    "    signal_power = tf.reduce_mean(waveform ** 2)\n",
    "    snr_ratio = tf.pow(10.0, desired_snr_db / 10.0)\n",
    "    scaling_factor = tf.sqrt(signal_power / (snr_ratio * noise_power + 1e-10))\n",
    "    noisy_waveform = waveform + scaling_factor * noise\n",
    "    return tf.clip_by_value(noisy_waveform, -1.0, 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02521fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_label(label, label_dir, processor, background_noises, params, output_dir, batch_size, batch_count):\n",
    "    label_to_index = {\"yes\": 0, \"no\": 1, \"background_noises\": 2, \"silence\": 3}\n",
    "    if label not in label_to_index:\n",
    "        raise ValueError(f\"Label '{label}' not found in label_to_index mapping.\")\n",
    "    label_index = label_to_index[label]\n",
    "    print(f\"Processing label: {label}, label_index: {label_index}\")\n",
    "    batch_data = []\n",
    "    batch_labels = []\n",
    "\n",
    "    if label == \"background_noises\":\n",
    "        # Generate around 40000 samples by randomly sampling the background noise files\n",
    "        num_samples_to_generate = 40000\n",
    "        generator = generate_random_chunks(background_noises, params, num_samples_to_generate)\n",
    "        for chunk in generator:\n",
    "            features = processor.process_waveform(chunk)\n",
    "            batch_data.append(features.numpy())\n",
    "            batch_labels.append(label_index)\n",
    "            if len(batch_data) >= batch_size:\n",
    "                save_batch_to_disk(batch_data, batch_labels, output_dir, batch_count, label)\n",
    "                batch_data, batch_labels = [], []\n",
    "                batch_count += 1\n",
    "        if batch_data:\n",
    "            save_batch_to_disk(batch_data, batch_labels, output_dir, batch_count, label)\n",
    "            batch_count += 1\n",
    "\n",
    "    elif label == \"silence\":\n",
    "        # Generate around 40000 silence samples\n",
    "        num_samples_to_generate = 40000\n",
    "        for _ in range(num_samples_to_generate):\n",
    "            # Generate silence waveform (zeros)\n",
    "            waveform = tf.zeros([params.desired_samples], dtype=tf.float32)\n",
    "            features = processor.process_waveform(waveform)\n",
    "            batch_data.append(features.numpy())\n",
    "            batch_labels.append(label_index)\n",
    "            if len(batch_data) >= batch_size:\n",
    "                save_batch_to_disk(batch_data, batch_labels, output_dir, batch_count, label)\n",
    "                batch_data, batch_labels = [], []\n",
    "                batch_count += 1\n",
    "        if batch_data:\n",
    "            save_batch_to_disk(batch_data, batch_labels, output_dir, batch_count, label)\n",
    "            batch_count += 1\n",
    "\n",
    "    else:\n",
    "        for filename in os.listdir(label_dir):\n",
    "            if filename.endswith(\".wav\"):\n",
    "                filepath = os.path.join(label_dir, filename)\n",
    "                waveform = processor.load_wav_file(filepath)\n",
    "                features = processor.process_waveform(waveform)\n",
    "                batch_data.append(features.numpy())\n",
    "                batch_labels.append(label_index)\n",
    "\n",
    "                for noise_waveform in background_noises:\n",
    "                    # Ensure noise and waveform have the same length\n",
    "                    total_noise_samples = noise_waveform.shape[0]\n",
    "                    desired_samples = waveform.shape[0]\n",
    "                    if total_noise_samples > desired_samples:\n",
    "                        max_start = total_noise_samples - desired_samples\n",
    "                        start_idx = np.random.randint(0, max_start)\n",
    "                        noise_segment = noise_waveform[start_idx:start_idx + desired_samples]\n",
    "                    else:\n",
    "                        # If noise is shorter, pad it\n",
    "                        padding = tf.zeros([desired_samples - total_noise_samples], dtype=tf.float32)\n",
    "                        noise_segment = tf.concat([noise_waveform, padding], 0)\n",
    "\n",
    "                    augmented_waveform = add_background_noise(waveform, noise_segment, desired_snr_db=20)\n",
    "                    augmented_features = processor.process_waveform(augmented_waveform)\n",
    "                    batch_data.append(augmented_features.numpy())\n",
    "                    batch_labels.append(label_index)\n",
    "\n",
    "                if len(batch_data) >= batch_size:\n",
    "                    save_batch_to_disk(batch_data, batch_labels, output_dir, batch_count, label)\n",
    "                    batch_data, batch_labels = [], []\n",
    "                    batch_count += 1\n",
    "\n",
    "        if batch_data:\n",
    "            save_batch_to_disk(batch_data, batch_labels, output_dir, batch_count, label)\n",
    "            batch_count += 1  # Increment after saving\n",
    "\n",
    "    return batch_count  # Return the updated batch_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3da4228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_batch_to_disk(batch_data, batch_labels, output_dir, batch_count, label):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    np.save(os.path.join(output_dir, f\"{label}_batch_{batch_count}_features.npy\"), np.array(batch_data))\n",
    "    np.save(os.path.join(output_dir, f\"{label}_batch_{batch_count}_labels.npy\"), np.array(batch_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "652775bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_batches(output_dir, final_features_file, final_labels_file):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Get lists of feature and label files\n",
    "    feature_files = sorted([f for f in os.listdir(output_dir) if 'features' in f])\n",
    "    label_files = sorted([f for f in os.listdir(output_dir) if 'labels' in f])\n",
    "\n",
    "    # Ensure the lists are sorted and matched\n",
    "    if len(feature_files) != len(label_files):\n",
    "        raise ValueError(\"Number of feature files and label files do not match.\")\n",
    "\n",
    "    for feature_file, label_file in zip(feature_files, label_files):\n",
    "        features = np.load(os.path.join(output_dir, feature_file))\n",
    "        labels = np.load(os.path.join(output_dir, label_file))\n",
    "        all_features.append(features)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    all_features = np.concatenate(all_features, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    np.save(os.path.join(output_dir, final_features_file), all_features)\n",
    "    np.save(os.path.join(output_dir, final_labels_file), all_labels)\n",
    "    print(f\"Combined features shape: {all_features.shape}\")\n",
    "    print(f\"Combined labels shape: {all_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fd4afcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main processing\n",
    "data_dir = \"dataset_small\"\n",
    "output_dir = \"processed_dataset_small\"\n",
    "batch_size = 50\n",
    "\n",
    "params = FeatureParams(\n",
    "    sample_rate=16000,\n",
    "    window_size_ms=30.0,\n",
    "    window_stride_ms=20.0,\n",
    "    num_mel_bins=40,\n",
    "    lower_frequency=125.0,\n",
    "    upper_frequency=7500.0,\n",
    "    clip_duration_ms=1000.0\n",
    ")\n",
    "background_noises = load_background_noises(os.path.join(data_dir, \"background_noises\"), params)\n",
    "processor = AudioProcessor(params)\n",
    "\n",
    "labels_to_process = ['yes', 'no', 'background_noises', 'silence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ddf08fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: yes, label_index: 0\n",
      "Processing label: no, label_index: 1\n",
      "Processing label: background_noises, label_index: 2\n",
      "Processing label: silence, label_index: 3\n"
     ]
    }
   ],
   "source": [
    "batch_count = 0  # Initialize batch_count\n",
    "for label in labels_to_process:\n",
    "    if label == 'silence':\n",
    "        label_dir = None\n",
    "    else:\n",
    "        label_dir = os.path.join(data_dir, label)\n",
    "        if not os.path.isdir(label_dir):\n",
    "            continue\n",
    "    batch_count = process_and_save_label(label, label_dir, processor, background_noises, params, output_dir, batch_size, batch_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea0320c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined features shape: (271086, 49, 40)\n",
      "Combined labels shape: (271086,)\n"
     ]
    }
   ],
   "source": [
    "combine_batches(output_dir, \"features.npy\", \"labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30151e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (271086, 49, 40)\n",
      "Labels shape: (271086,)\n",
      "\n",
      "Unique Labels and Counts:\n",
      "Label: 0, Count: 100428\n",
      "Label: 1, Count: 90643\n",
      "Label: 2, Count: 40015\n",
      "Label: 3, Count: 40000\n",
      "\n",
      "Labels Mapped to Names:\n",
      "Label: yes, Count: 100428\n",
      "Label: no, Count: 90643\n",
      "Label: background_noises, Count: 40015\n",
      "Label: silence, Count: 40000\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"processed_dataset_small\"\n",
    "\n",
    "# Load the combined features and labels\n",
    "features = np.load(os.path.join(output_dir, \"features.npy\"))\n",
    "labels = np.load(os.path.join(output_dir, \"labels.npy\"))\n",
    "\n",
    "print(\"Features shape:\", features.shape)\n",
    "print(\"Labels shape:\", labels.shape)\n",
    "\n",
    "# Check the distribution of labels\n",
    "unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "print(\"\\nUnique Labels and Counts:\")\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    print(f\"Label: {label}, Count: {count}\")\n",
    "\n",
    "# Map label indices to label names\n",
    "label_to_name = {0: \"yes\", 1: \"no\", 2: \"background_noises\", 3: \"silence\"}\n",
    "print(\"\\nLabels Mapped to Names:\")\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    name = label_to_name.get(label, \"Unknown\")\n",
    "    print(f\"Label: {name}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4aa65a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2723003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf70a52e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
