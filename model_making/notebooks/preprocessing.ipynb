{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2db7517d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow-io in /share/pkg.7/tensorflow/2.11.0/install/lib/python3.10/site-packages (0.30.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.30.0 in /share/pkg.7/tensorflow/2.11.0/install/lib/python3.10/site-packages (from tensorflow-io) (0.30.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91f56ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import wave\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "import tensorflow_io as tfio\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af5d8f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager execution enabled: True\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.enable_eager_execution()\n",
    "print(\"Eager execution enabled:\", tf.executing_eagerly())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "626c5a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sample_rate(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                filepath = os.path.join(root, file)\n",
    "                try:\n",
    "                    with wave.open(filepath, 'rb') as wav_file:\n",
    "                        sample_rate = wav_file.getframerate()\n",
    "                        print(f\"File: {filepath}, Sample Rate: {sample_rate} Hz\")\n",
    "                except wave.Error as e:\n",
    "                    print(f\"Error reading {filepath}: {e}\")\n",
    "\n",
    "data_dir = 'dataset_small'  # Replace with your data directory\n",
    "#check_sample_rate(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "482dc653",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FeatureParams:\n",
    "    sample_rate: int = 16000  # Audio sample rate\n",
    "    window_size_ms: float = 30.0  # Window size in milliseconds\n",
    "    window_stride_ms: float = 20.0  # Window stride in milliseconds\n",
    "    num_mel_bins: int = 40  # Number of Mel bins\n",
    "    lower_frequency: float = 125.0  # Lower frequency limit in Hz\n",
    "    upper_frequency: float = 7500.0  # Upper frequency limit in Hz\n",
    "    fft_length: int = None  # FFT length\n",
    "    clip_duration_ms: float = 1000.0  # Duration to clip/pad audio in milliseconds\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.window_length_samples = int(self.sample_rate * self.window_size_ms / 1000)\n",
    "        self.window_step_samples = int(self.sample_rate * self.window_stride_ms / 1000)\n",
    "        if self.fft_length is None:\n",
    "            self.fft_length = 2 ** int(np.ceil(np.log2(self.window_length_samples)))\n",
    "        self.desired_samples = int(self.sample_rate * self.clip_duration_ms / 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20ffcef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_background_noise(background_file, params, chunk_duration_ms=1000):\n",
    "    \"\"\"\n",
    "    Split the background noise file into smaller chunks.\n",
    "    \"\"\"\n",
    "    processor = AudioProcessor(params)\n",
    "    waveform = processor.load_wav_file(background_file)\n",
    "    chunk_samples = int(params.sample_rate * chunk_duration_ms / 1000)\n",
    "    num_chunks = len(waveform) // chunk_samples\n",
    "    return [waveform[i * chunk_samples:(i + 1) * chunk_samples] for i in range(num_chunks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b04ce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_background_noises(background_file: str, params: FeatureParams) -> list[tf.Tensor]:\n",
    "    \"\"\"\n",
    "    Load and preprocess a single long background noise file, splitting it into smaller clips.\n",
    "    \"\"\"\n",
    "    processor = AudioProcessor(params)\n",
    "    print(f\"Processing background noise file: {background_file}\")\n",
    "    noise_waveform = processor.load_wav_file(background_file)\n",
    "    \n",
    "    # Calculate the number of clips to generate\n",
    "    clip_length = params.desired_samples  # Each clip matches the audio duration\n",
    "    num_clips = tf.shape(noise_waveform)[0] // clip_length\n",
    "\n",
    "    # Split the long noise waveform into multiple shorter clips\n",
    "    background_clips = []\n",
    "    for i in range(num_clips.numpy()):  # Convert tensor to integer for iteration\n",
    "        start_idx = i * clip_length\n",
    "        end_idx = start_idx + clip_length\n",
    "        clip = noise_waveform[start_idx:end_idx]\n",
    "        background_clips.append(clip)\n",
    "\n",
    "    print(f\"Generated {len(background_clips)} background noise clips.\")\n",
    "    return background_clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02521fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_background_noise(waveform: tf.Tensor, background_noises: list[tf.Tensor], desired_snr_db: float) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Add background noise to a waveform with the desired Signal-to-Noise Ratio (SNR).\n",
    "    \"\"\"\n",
    "    # Randomly select a background noise clip\n",
    "    noise_clip = random.choice(background_noises)\n",
    "    noise_clip = noise_clip[:len(waveform)]  # Ensure matching length\n",
    "\n",
    "    # Calculate signal and noise power\n",
    "    signal_power = tf.reduce_mean(waveform ** 2)\n",
    "    noise_power = tf.reduce_mean(noise_clip ** 2)\n",
    "\n",
    "    # Scale noise to match desired SNR\n",
    "    scaling_factor = tf.sqrt(signal_power / (noise_power * 10 ** (desired_snr_db / 10)))\n",
    "    scaled_noise = noise_clip * scaling_factor\n",
    "\n",
    "    # Add scaled noise to the waveform\n",
    "    return waveform + scaled_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3da4228",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioProcessor:\n",
    "    def __init__(self, params: FeatureParams):\n",
    "        self.params = params\n",
    "\n",
    "    def load_wav_file(self, filename: str) -> tf.Tensor:\n",
    "        audio_binary = tf.io.read_file(filename)\n",
    "        waveform, sample_rate = tf.audio.decode_wav(audio_binary, desired_channels=1)\n",
    "        waveform = tf.squeeze(waveform, axis=-1)\n",
    "        sample_rate = tf.cast(sample_rate, tf.int32)\n",
    "        #print(sample_rate.shape)\n",
    "        #print(sample_rate)\n",
    "        #if sample_rate != self.params.sample_rate:\n",
    "        #    print(f\"Warning: Sample rate mismatch for {filename}. Resampling from {sample_rate} Hz to {self.params.sample_rate} Hz.\")\n",
    "        #    # Resample the waveform\n",
    "        #    waveform = tfio.audio.resample(waveform, rate_in=tf.cast(sample_rate, tf.int64), rate_out=self.params.sample_rate)\n",
    "        # Trim or pad waveform to desired_samples\n",
    "        waveform = waveform[:self.params.desired_samples]\n",
    "        zero_padding = tf.zeros(\n",
    "            [self.params.desired_samples - tf.shape(waveform)[0]], dtype=tf.float32)\n",
    "        waveform = tf.concat([waveform, zero_padding], 0)\n",
    "        return waveform\n",
    "\n",
    "    def process_waveform(self, waveform: tf.Tensor) -> tf.Tensor:\n",
    "        # Generate frames\n",
    "        frames = tf.signal.frame(\n",
    "            waveform,\n",
    "            self.params.window_length_samples,\n",
    "            self.params.window_step_samples,\n",
    "            pad_end=True\n",
    "        )\n",
    "        # Apply Hann window\n",
    "        window = tf.signal.hann_window(self.params.window_length_samples)\n",
    "        windowed_frames = frames * window\n",
    "        # Compute FFT\n",
    "        fft = tf.signal.rfft(windowed_frames, [self.params.fft_length])\n",
    "        power_spectrum = tf.abs(fft) ** 2\n",
    "        # Apply Mel filter bank\n",
    "        num_spectrogram_bins = self.params.fft_length // 2 + 1\n",
    "        linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
    "            self.params.num_mel_bins,\n",
    "            num_spectrogram_bins,\n",
    "            self.params.sample_rate,\n",
    "            self.params.lower_frequency,\n",
    "            self.params.upper_frequency\n",
    "        )\n",
    "        mel_spectrogram = tf.tensordot(power_spectrum, linear_to_mel_weight_matrix, 1)\n",
    "        mel_spectrogram.set_shape(power_spectrum.shape[:-1].concatenate(\n",
    "            [self.params.num_mel_bins]))\n",
    "        # Compute log-mel spectrogram\n",
    "        log_mel_spectrogram = tf.math.log(mel_spectrogram + 1e-6)\n",
    "\n",
    "        # Ensure fixed number of frames\n",
    "        expected_num_frames = 1 + (self.params.desired_samples - self.params.window_length_samples) // self.params.window_step_samples\n",
    "        num_frames = tf.shape(log_mel_spectrogram)[0]\n",
    "        num_padding_frames = expected_num_frames - num_frames\n",
    "\n",
    "        # Pad or truncate to expected_num_frames without using Python conditionals\n",
    "        num_padding_frames = tf.maximum(num_padding_frames, 0)\n",
    "        log_mel_spectrogram = tf.pad(log_mel_spectrogram, [[0, num_padding_frames], [0, 0]], \"CONSTANT\")\n",
    "        log_mel_spectrogram = log_mel_spectrogram[:expected_num_frames, :]\n",
    "\n",
    "        return log_mel_spectrogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bddaa094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(data_dir: str, params: FeatureParams):\n",
    "    processor = AudioProcessor(params)\n",
    "    labels = sorted(os.listdir(data_dir))\n",
    "    label_to_index = {label: index for index, label in enumerate(labels)}\n",
    "    data = []\n",
    "    data_labels = []\n",
    "    for label in labels:\n",
    "        label_dir = os.path.join(data_dir, label)\n",
    "        if not os.path.isdir(label_dir):\n",
    "            continue\n",
    "        print(f\"Processing label: {label}\")\n",
    "        files = os.listdir(label_dir)\n",
    "        for filename in files:\n",
    "            if filename.endswith('.wav'):\n",
    "                filepath = os.path.join(label_dir, filename)\n",
    "                waveform = processor.load_wav_file(filepath)\n",
    "                if waveform is None:\n",
    "                    continue\n",
    "                features = processor.process_waveform(waveform)\n",
    "                features_np = features.numpy()\n",
    "                data.append(features_np)\n",
    "                data_labels.append(label_to_index[label])\n",
    "    return np.array(data), np.array(data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "652775bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_label(label, label_dir, processor, background_noises, params, output_dir, batch_size):\n",
    "    \"\"\"\n",
    "    Process the features and labels for a single label and save them in batches.\n",
    "    \"\"\"\n",
    "    print(f\"Processing label: {label}\")\n",
    "    batch_data = []\n",
    "    batch_labels = []\n",
    "    batch_count = 0\n",
    "\n",
    "    files = os.listdir(label_dir)\n",
    "    for filename in files:\n",
    "        if filename.endswith('.wav'):\n",
    "            filepath = os.path.join(label_dir, filename)\n",
    "            waveform = processor.load_wav_file(filepath)\n",
    "            if waveform is None:\n",
    "                continue\n",
    "\n",
    "            # Original waveform\n",
    "            features = processor.process_waveform(waveform)\n",
    "            batch_data.append(features.numpy())\n",
    "            batch_labels.append(label)\n",
    "\n",
    "            # Augment with background noise\n",
    "            for noise in background_noises:\n",
    "                augmented_waveform = add_background_noise(waveform, noise, desired_snr_db=20)\n",
    "                augmented_features = processor.process_waveform(augmented_waveform)\n",
    "                batch_data.append(augmented_features.numpy())\n",
    "                batch_labels.append(label)\n",
    "\n",
    "            # Save batch to disk\n",
    "            if len(batch_data) >= batch_size:\n",
    "                save_batch_to_disk(batch_data, batch_labels, output_dir, label, batch_count)\n",
    "                batch_data = []\n",
    "                batch_labels = []\n",
    "                batch_count += 1\n",
    "\n",
    "    # Save any remaining data\n",
    "    if batch_data:\n",
    "        save_batch_to_disk(batch_data, batch_labels, output_dir, label, batch_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51c7fb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_batch_to_disk(batch_data, batch_labels, output_dir, label, batch_count):\n",
    "    \"\"\"\n",
    "    Save a batch of data to disk for a specific label.\n",
    "    \"\"\"\n",
    "    label_dir = os.path.join(output_dir, label)\n",
    "    os.makedirs(label_dir, exist_ok=True)\n",
    "    batch_file = os.path.join(label_dir, f'batch_{batch_count}')\n",
    "    np.save(f'{batch_file}_features.npy', batch_data)\n",
    "    np.save(f'{batch_file}_labels.npy', batch_labels)\n",
    "    print(f\"Saved batch {batch_count} for label {label} to disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e05edf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset_with_noise_in_batches(data_dir: str, background_file: str, params: FeatureParams, batch_size: int, output_dir: str):\n",
    "    \"\"\"\n",
    "    Process the dataset with background noise augmentation in batches.\n",
    "    \"\"\"\n",
    "    processor = AudioProcessor(params)\n",
    "    background_noises = load_background_noises(background_file, params)\n",
    "    labels = sorted(os.listdir(data_dir))\n",
    "    label_to_index = {label: index for index, label in enumerate(labels)}\n",
    "    label_to_index[\"_background_noise_\"] = len(labels)  # Add index for noise class\n",
    "\n",
    "    batch_data = []\n",
    "    batch_labels = []\n",
    "    batch_count = 0\n",
    "\n",
    "    for label in labels:\n",
    "        label_dir = os.path.join(data_dir, label)\n",
    "        if not os.path.isdir(label_dir):\n",
    "            continue\n",
    "        print(f\"Processing label: {label}\")\n",
    "        files = os.listdir(label_dir)\n",
    "        for filename in files:\n",
    "            if filename.endswith('.wav'):\n",
    "                filepath = os.path.join(label_dir, filename)\n",
    "                waveform = processor.load_wav_file(filepath)\n",
    "                if waveform is None:\n",
    "                    continue\n",
    "\n",
    "                # Original waveform\n",
    "                features = processor.process_waveform(waveform)\n",
    "                batch_data.append(features.numpy())\n",
    "                batch_labels.append(label_to_index[label])\n",
    "\n",
    "                # Augment with background noise\n",
    "                augmented_waveform = add_background_noise(waveform, background_noises, desired_snr_db=20)\n",
    "                augmented_features = processor.process_waveform(augmented_waveform)\n",
    "                batch_data.append(augmented_features.numpy())\n",
    "                batch_labels.append(label_to_index[label])\n",
    "\n",
    "                # Save batch to disk if it reaches the batch size\n",
    "                if len(batch_data) >= batch_size:\n",
    "                    save_batch_to_disk(batch_data, batch_labels, output_dir, batch_count)\n",
    "                    batch_data = []\n",
    "                    batch_labels = []\n",
    "                    batch_count += 1\n",
    "\n",
    "    # Add background noise as a separate class\n",
    "    for noise_waveform in background_noises:\n",
    "        features = processor.process_waveform(noise_waveform)\n",
    "        batch_data.append(features.numpy())\n",
    "        batch_labels.append(label_to_index[\"_background_noise_\"])\n",
    "\n",
    "        if len(batch_data) >= batch_size:\n",
    "            save_batch_to_disk(batch_data, batch_labels, output_dir, batch_count)\n",
    "            batch_data = []\n",
    "            batch_labels = []\n",
    "            batch_count += 1\n",
    "\n",
    "    # Save any remaining data\n",
    "    if batch_data:\n",
    "        save_batch_to_disk(batch_data, batch_labels, output_dir, batch_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d56b3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_batch_to_disk(batch_data, batch_labels, output_dir, batch_count):\n",
    "    \"\"\"\n",
    "    Save a batch of data to disk.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    batch_file = os.path.join(output_dir, f'batch_{batch_count}')\n",
    "    np.save(f'{batch_file}_features.npy', batch_data)\n",
    "    np.save(f'{batch_file}_labels.npy', batch_labels)\n",
    "    print(f\"Saved batch {batch_count} to disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b161501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_processed_data(features: np.ndarray, labels: np.ndarray, output_dir: str):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    np.save(os.path.join(output_dir, 'features.npy'), features)\n",
    "    np.save(os.path.join(output_dir, 'labels.npy'), labels)\n",
    "    print(f\"Saved features to {os.path.join(output_dir, 'features.npy')}\")\n",
    "    print(f\"Saved labels to {os.path.join(output_dir, 'labels.npy')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f14456",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'dataset_small'  # Replace with your data directory\n",
    "background_file = 'dataset_small/background_noises/white_noise.wav'\n",
    "output_dir = 'processed_dataset_small'  # Replace with your desired output directory\n",
    "batch_size = 50\n",
    "\n",
    "# Initialize parameters\n",
    "params = FeatureParams(\n",
    "    sample_rate=16000,\n",
    "    window_size_ms=30.0,\n",
    "    window_stride_ms=20.0,\n",
    "    num_mel_bins=40,\n",
    "    lower_frequency=125.0,\n",
    "    upper_frequency=7500.0,\n",
    "    clip_duration_ms=1000.0\n",
    ")\n",
    "\n",
    "# Process dataset\n",
    "#features, labels = process_dataset_with_noise_in_batches(\n",
    "#    data_dir, background_file, params, batch_size, output_dir\n",
    "#)\n",
    "\n",
    "# Save processed data\n",
    "#save_processed_data(features, labels, output_dir)\n",
    "\n",
    "# Split background noise into smaller chunks\n",
    "background_noises = split_background_noise(background_file, params)\n",
    "\n",
    "# Process each label individually\n",
    "labels = sorted(os.listdir(data_dir))\n",
    "processor = AudioProcessor(params)\n",
    "\n",
    "for label in labels:\n",
    "    label_dir = os.path.join(data_dir, label)\n",
    "    if not os.path.isdir(label_dir):\n",
    "        continue\n",
    "    process_and_save_label(label, label_dir, processor, background_noises, params, output_dir, batch_size)\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047bae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Eager execution enabled:\", tf.executing_eagerly())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe40117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd4afcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
